{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import pandas as pd\n",
    "import re\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "import contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"D:\\\\vit\\\\sem6\\\\tarp\\\\extracted_comments_v1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>cz6nfd</td>\n",
       "      <td>New wiki on how to avoid accidentally encourag...</td>\n",
       "      <td>SuicideWatch</td>\n",
       "      <td>We've been seeing a worrying increase in pro-s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>pl9suy</td>\n",
       "      <td>Please remember that NO ACTIVISM of any kind i...</td>\n",
       "      <td>SuicideWatch</td>\n",
       "      <td>Activism, i.e. advocating or fundraising for s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>11b73ta</td>\n",
       "      <td>\"Things will get better\" No, they won't.</td>\n",
       "      <td>SuicideWatch</td>\n",
       "      <td>Actually, no one has told me that it would get...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>11b2cqz</td>\n",
       "      <td>therapy only teaches me there's no one who can...</td>\n",
       "      <td>SuicideWatch</td>\n",
       "      <td>I've been in therapy for 6 years on my own dim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>11b8ti7</td>\n",
       "      <td>wishing i didn't exist, never came into existe...</td>\n",
       "      <td>SuicideWatch</td>\n",
       "      <td>does anyone else have the constant desire to j...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>94</td>\n",
       "      <td>11b4oy8</td>\n",
       "      <td>void</td>\n",
       "      <td>SuicideWatch</td>\n",
       "      <td>I feel so empty I just want to feel something ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>95</td>\n",
       "      <td>11bcdb7</td>\n",
       "      <td>There is only a few things in this world keepi...</td>\n",
       "      <td>SuicideWatch</td>\n",
       "      <td>I am 23F, and for the past 8 years of my life ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>97</td>\n",
       "      <td>11bcaey</td>\n",
       "      <td>Everything is right!</td>\n",
       "      <td>SuicideWatch</td>\n",
       "      <td>I am in school for my passion. I am in a beaut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>98</td>\n",
       "      <td>11bc9tc</td>\n",
       "      <td>i might be ok at this exact time but at litera...</td>\n",
       "      <td>SuicideWatch</td>\n",
       "      <td>i scare myself</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>99</td>\n",
       "      <td>11bc813</td>\n",
       "      <td>my friends keep telling me to hurry up and app...</td>\n",
       "      <td>SuicideWatch</td>\n",
       "      <td>everything sucks. I don’t have any passions, h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>91 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0       id                                              title  \\\n",
       "0            0   cz6nfd  New wiki on how to avoid accidentally encourag...   \n",
       "1            1   pl9suy  Please remember that NO ACTIVISM of any kind i...   \n",
       "2            2  11b73ta           \"Things will get better\" No, they won't.   \n",
       "3            3  11b2cqz  therapy only teaches me there's no one who can...   \n",
       "4            4  11b8ti7  wishing i didn't exist, never came into existe...   \n",
       "..         ...      ...                                                ...   \n",
       "94          94  11b4oy8                                               void   \n",
       "95          95  11bcdb7  There is only a few things in this world keepi...   \n",
       "97          97  11bcaey                               Everything is right!   \n",
       "98          98  11bc9tc  i might be ok at this exact time but at litera...   \n",
       "99          99  11bc813  my friends keep telling me to hurry up and app...   \n",
       "\n",
       "       subreddit                                               text  \n",
       "0   SuicideWatch  We've been seeing a worrying increase in pro-s...  \n",
       "1   SuicideWatch  Activism, i.e. advocating or fundraising for s...  \n",
       "2   SuicideWatch  Actually, no one has told me that it would get...  \n",
       "3   SuicideWatch  I've been in therapy for 6 years on my own dim...  \n",
       "4   SuicideWatch  does anyone else have the constant desire to j...  \n",
       "..           ...                                                ...  \n",
       "94  SuicideWatch  I feel so empty I just want to feel something ...  \n",
       "95  SuicideWatch  I am 23F, and for the past 8 years of my life ...  \n",
       "97  SuicideWatch  I am in school for my passion. I am in a beaut...  \n",
       "98  SuicideWatch                                     i scare myself  \n",
       "99  SuicideWatch  everything sucks. I don’t have any passions, h...  \n",
       "\n",
       "[91 rows x 5 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n",
    "df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(\"Unnamed: 0\",axis=1)\n",
    "df = df[df['text'].notna()]\n",
    "\n",
    "dataset=df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94    I feel so empty I just want to feel something ...\n",
       "95    I am 23F, and for the past 8 years of my life ...\n",
       "97    I am in school for my passion. I am in a beaut...\n",
       "98                                       i scare myself\n",
       "99    everything sucks. I do not have any passions, ...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cleaning_contractions(text):\n",
    "    text=text.split()\n",
    "    corrected=[]\n",
    "    for word in text:\n",
    "        corrected.append(contractions.fix(word))\n",
    "    return \" \".join(corrected)\n",
    "dataset['text']=dataset['text'].apply(lambda x: cleaning_contractions(x))\n",
    "dataset[\"text\"].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94    I feel so empty I just want to feel something ...\n",
       "95    I am 23F, and for the past 8 years of my life ...\n",
       "97    I am in school for my passion. I am in a beaut...\n",
       "98                                       i scare myself\n",
       "99    everything sucks. I do not have any passions, ...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import emoji\n",
    "def convert_emoji(text):\n",
    "    return emoji.demojize(text )\n",
    "dataset['text']=dataset['text'].apply(lambda x: convert_emoji(x))\n",
    "dataset[\"text\"].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "94    I feel so empty I just want to feel something ...\n",
       "95    I am 23F  and for the past 8 years of my life ...\n",
       "97    I am in school for my passion  I am in a beaut...\n",
       "98                                       i scare myself\n",
       "99    everything sucks  I do not have any passions  ...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english_punctuations = string.punctuation\n",
    "punctuations_list = english_punctuations\n",
    "print(punctuations_list)\n",
    "def cleaning_punctuations(text):\n",
    "    return re.sub(re.compile(\"[\"+punctuations_list+\"‼️’]\"),\" \",text)\n",
    "dataset['text']= dataset['text'].apply(lambda x: cleaning_punctuations(x))\n",
    "dataset['text'].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94    I feel so empty I just want to feel something ...\n",
       "95    I am 23F  and for the past 8 years of my life ...\n",
       "97    I am in school for my passion  I am in a beaut...\n",
       "98                                       i scare myself\n",
       "99    everything sucks  I do not have any passions  ...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cleaning_repeating_char(text):\n",
    "    return re.sub(r'(.)1+', r'1', text)\n",
    "dataset['text'] = dataset['text'].apply(lambda x: cleaning_repeating_char(x))\n",
    "dataset['text'].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94    I feel so empty I just want to feel something ...\n",
       "95    I am 23F  and for the past 8 years of my life ...\n",
       "97    I am in school for my passion  I am in a beaut...\n",
       "98                                       i scare myself\n",
       "99    everything sucks  I do not have any passions  ...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cleaning_URLs(data):\n",
    "    return re.sub('((www.[^s]+)|(https?://[^s]+))',' ',data)\n",
    "dataset['text'] = dataset['text'].apply(lambda x: cleaning_URLs(x))\n",
    "dataset['text'].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94    I feel so empty I just want to feel something ...\n",
       "95    I am F  and for the past  years of my life I h...\n",
       "97    I am in school for my passion  I am in a beaut...\n",
       "98                                       i scare myself\n",
       "99    everything sucks  I do not have any passions  ...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cleaning_numbers(data):\n",
    "    return re.sub('[0-9]+', '', data)\n",
    "dataset['text'] = dataset['text'].apply(lambda x: cleaning_numbers(x))\n",
    "dataset['text'].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94    I feel so empty I just want to feel something ...\n",
       "95    I am F and for the past years of my life I hav...\n",
       "97    I am in school for my passion I am in a beauti...\n",
       "98                                       i scare myself\n",
       "99    everything sucks I do not have any passions ho...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def depure_data(data):\n",
    "    \n",
    "    #Removing URLs with a regular expression\n",
    "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    data = url_pattern.sub(r'', data)\n",
    "    # Remove Emails\n",
    "    data = re.sub('\\S*@\\S*\\s?', '', data)\n",
    "    # Remove new line characters\n",
    "    data = re.sub('\\\\s+', ' ', data)\n",
    "        \n",
    "    return data\n",
    "dataset['text'] = dataset['text'].apply(lambda x:depure_data(x))\n",
    "dataset['text'].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94    I feel so empty I just want to feel something ...\n",
       "95    I am F and for the past years of my life I hav...\n",
       "97    I am in school for my passion I am in a beauti...\n",
       "98                                       i scare myself\n",
       "99    everything sucks I do not have any passions ho...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cleaning_COMPLETE(data):\n",
    "    return re.sub('[^a-zA-Z\\s]', ' ', data)\n",
    "dataset['text'] = dataset['text'].apply(lambda x: cleaning_COMPLETE(x))\n",
    "dataset['text'].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\metul\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'him',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " 'if',\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'nor',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " 'your',\n",
       " 'yours'}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stop_words = set(stopwords.words('english')) - {'not', 'no', 'but', 'because',\"against\",\"and\",\"or\",\"myself\",\"herself\",\"himself\",\"ourselves\",\"themselves\",\"until\",\"me\",\"I\",\"yourself\",\"yourselves\",\"you\"}\n",
    "stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94    feel empty want feel something nothing brings ...\n",
       "95    F and past years life heavily medicated and in...\n",
       "97    school passion beautiful happy and committed l...\n",
       "98                                         scare myself\n",
       "99    everything sucks not passions hobbies or inter...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_stopwords(data):\n",
    "    words = data.split()\n",
    "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "    filtered_text = ' '.join(filtered_words)\n",
    "    return filtered_text\n",
    "dataset['text'] = dataset['text'].apply(lambda x: clean_stopwords(x))\n",
    "dataset['text'].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cz6nfd</td>\n",
       "      <td>New wiki on how to avoid accidentally encourag...</td>\n",
       "      <td>SuicideWatch</td>\n",
       "      <td>seeing worrying increase pro suicide content s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pl9suy</td>\n",
       "      <td>Please remember that NO ACTIVISM of any kind i...</td>\n",
       "      <td>SuicideWatch</td>\n",
       "      <td>Activism e advocating or fundraising social ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11b73ta</td>\n",
       "      <td>\"Things will get better\" No, they won't.</td>\n",
       "      <td>SuicideWatch</td>\n",
       "      <td>Actually no one told me would get better time ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11b2cqz</td>\n",
       "      <td>therapy only teaches me there's no one who can...</td>\n",
       "      <td>SuicideWatch</td>\n",
       "      <td>therapy years dime and feel worse every time t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11b8ti7</td>\n",
       "      <td>wishing i didn't exist, never came into existe...</td>\n",
       "      <td>SuicideWatch</td>\n",
       "      <td>anyone else constant desire not fucking exist ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                              title     subreddit  \\\n",
       "0   cz6nfd  New wiki on how to avoid accidentally encourag...  SuicideWatch   \n",
       "1   pl9suy  Please remember that NO ACTIVISM of any kind i...  SuicideWatch   \n",
       "2  11b73ta           \"Things will get better\" No, they won't.  SuicideWatch   \n",
       "3  11b2cqz  therapy only teaches me there's no one who can...  SuicideWatch   \n",
       "4  11b8ti7  wishing i didn't exist, never came into existe...  SuicideWatch   \n",
       "\n",
       "                                                text  \n",
       "0  seeing worrying increase pro suicide content s...  \n",
       "1  Activism e advocating or fundraising social ch...  \n",
       "2  Actually no one told me would get better time ...  \n",
       "3  therapy years dime and feel worse every time t...  \n",
       "4  anyone else constant desire not fucking exist ...  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "'''wantedrows=[]\n",
    "for i in range(len(dataset.text)):\n",
    "    if isinstance(dataset.iloc[i,0], float):\n",
    "        wantedrows.append(i)\n",
    "print(wantedrows)\n",
    "dataset =  dataset.drop(wantedrows, axis = 0)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset=dataset.dropna()\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_csv(\"D:\\\\vit\\\\sem6\\\\tarp\\\\extracted_comments_preprocessed.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f45bd3e5b831a322bd3f71c25d8b34384573d05cb8a4c9c57d323e5c6682e756"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
